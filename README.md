# ğŸ“ˆ Linear Regression from Scratch â€” Salary Prediction

## ğŸ“Œ DescriÃ§Ã£o do Projeto

Este projeto implementa **Linear Regression do zero (from scratch)** utilizando apenas **NumPy, Pandas e Matplotlib**, sem bibliotecas de machine learning como `scikit-learn`.

O objetivo Ã© **entender profundamente** como funciona:
- FunÃ§Ã£o de custo
- Gradiente
- Gradient Descent
- AtualizaÃ§Ã£o dos parÃ¢metros `w` e `b`

O modelo Ã© treinado para prever **salÃ¡rios com base em anos de experiÃªncia**.

---

## ğŸ§  MotivaÃ§Ã£o

Embora na prÃ¡tica seja comum usar algo como:
```python
from sklearn.linear_model import LinearRegression
```

este projeto existe para:
- entender o que acontece por baixo do capÃ´
- conectar matemÃ¡tica â†’ cÃ³digo â†’ aprendizado
- evitar usar ML como "caixa-preta"

---

## ğŸ“Š Dataset

- **Nome:** `Salary_Data.csv`
- **Features:**
  - `YearsExperience` â†’ anos de experiÃªncia
- **Target:**
  - `Salary` â†’ salÃ¡rio anual

Dataset simples, ideal para regressÃ£o linear bÃ¡sica.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Python 3
- NumPy
- Pandas
- Matplotlib
- Jupyter Notebook

---

## âš™ï¸ ImplementaÃ§Ã£o

### 1ï¸âƒ£ VisualizaÃ§Ã£o dos dados
Os dados sÃ£o plotados para verificar se existe relaÃ§Ã£o linear entre experiÃªncia e salÃ¡rio.

### 2ï¸âƒ£ FunÃ§Ã£o de custo (Mean Squared Error)
A funÃ§Ã£o de custo utilizada Ã©:

$$J(w,b) = \frac{1}{2m} \sum_{i=1}^{m} (wx^{(i)} + b - y^{(i)})^2$$

Implementada manualmente usando um loop.

### 3ï¸âƒ£ Gradiente
O gradiente da funÃ§Ã£o de custo em relaÃ§Ã£o aos parÃ¢metros Ã© calculado como:

$$\frac{\partial J}{\partial w} = \frac{1}{m} \sum (f(x) - y)x$$

$$\frac{\partial J}{\partial b} = \frac{1}{m} \sum (f(x) - y)$$

### 4ï¸âƒ£ Gradient Descent
O algoritmo de Gradient Descent Ã© usado para atualizar os parÃ¢metros:
```
w = w - Î± * âˆ‚J/âˆ‚w
b = b - Î± * âˆ‚J/âˆ‚b
```

- `Î±` (alpha) Ã© a learning rate
- O processo Ã© repetido por vÃ¡rias iteraÃ§Ãµes
- O custo Ã© monitorado para garantir convergÃªncia

---

## ğŸ“‰ Resultados

ApÃ³s o treinamento:
- O custo diminui progressivamente
- O modelo encontra uma reta que se ajusta bem aos dados
- A linha de regressÃ£o Ã© plotada sobre os pontos reais

---

## ğŸ§ª Experimentos

Durante o projeto, foram testados:
- Diferentes valores de learning rate (`alpha`)
- Diferentes nÃºmeros de iteraÃ§Ãµes
- ObservaÃ§Ã£o de divergÃªncia quando `alpha` Ã© muito alto
- Efeito do gradient descent ao longo do tempo

---

## ğŸš€ PrÃ³ximos Passos

- Separar dados em treino e teste
- Implementar Multiple Linear Regression
- Comparar com `sklearn.LinearRegression`
- Normalizar os dados
- Adicionar mÃ©tricas como RMSE e RÂ²

---

## ğŸ§  Aprendizados

- Gradient â‰  Gradient Descent
- Learning rate controla estabilidade do aprendizado
- RegressÃ£o linear tem soluÃ§Ã£o convexa
- Entender o bÃ¡sico facilita escalar para redes neurais

---

## ğŸ“ ObservaÃ§Ã£o Final

Este projeto tem foco educacional, priorizando clareza e entendimento sobre performance ou otimizaÃ§Ã£o.
